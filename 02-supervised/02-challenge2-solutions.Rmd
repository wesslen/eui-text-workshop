---
title: "Challenge 2"
author: Ryan Wesslen
date: July 27, 2016
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=TRUE, warning=FALSE, message=FALSE)
```

#### Supervised machine learning

Use the same dataset from Challenge 1. In this exercise, we're going to use supervised machine learning to determine the different words used by point Tweets versus polygon Tweet. Our goal is to better understand how Tweet content differs based on geo-location type.

1. Reload the dataset and `functions.R`. Change the geo.code column to a factor (`factor` function). We will build a machine learning classifier to determine the words that most characterize each geo-location type.

```{r}
tweets <- read.csv("./datasets/panthertweets.csv", stringsAsFactors = F)
source("functions.R")

tweets$geo.dummy <- ifelse(tweets$geo.type=="Point", 0, 1)
```

2. Create a training and test set, with 80% and 20%, respectively.

```{r}
set.seed(123)
training <- sample(1:nrow(tweets), floor(.80 * nrow(tweets)))
test <- (1:nrow(tweets))[1:nrow(tweets) %in% training == FALSE]
```

3. Construct the DFM. You may want to experiment with different preprocessing techniques until you achieve better performance. Hint - use the `trim` to remove words that are used at least five times (`minDoc = 5`).

```{r}
library(quanteda)
twcorpus <- corpus(tweets$body)
twdfm <- dfm(twcorpus, ignoredFeatures=c(
  stopwords("english"), "t.co", "https", "rt", "amp", "http", "t.c", "can"), 
  stem = TRUE, removeTwitter = TRUE)
twdfm <- trim(twdfm, minDoc = 10)
```

4. Now run the classifier. Then, compute the accuracy.

```{r}
library(glmnet)
require(doMC)
registerDoMC(cores=3)
ridge <- cv.glmnet(twdfm[training,], tweets$geo.dummy[training], 
    family="binomial", alpha=0, nfolds=5, parallel=TRUE,
    type.measure="deviance")
plot(ridge)

## function to compute accuracy
accuracy <- function(ypred, y){
    tab <- table(ypred, y)
    return(sum(diag(tab))/sum(tab))
}
# function to compute precision
precision <- function(ypred, y){
    tab <- table(ypred, y)
    return((tab[2,2])/(tab[2,1]+tab[2,2]))
}
# function to compute recall
recall <- function(ypred, y){
    tab <- table(ypred, y)
    return(tab[2,2]/(tab[1,2]+tab[2,2]))
}
# computing predicted values
preds <- predict(ridge, twdfm[test,], type="response") > mean(tweets$geo.dummy[test])
# confusion matrix
table(preds, tweets$geo.type[test])
# performance metrics
accuracy(preds, tweets$geo.type[test])
precision(preds, tweets$geo.type[test])
recall(preds, tweets$geo.type[test])
```

5. Identify the features that better predict that tweets the geo-location. What do you learn?
```{r}
# from the different values of lambda, let's pick the best one
best.lambda <- which(ridge$lambda==ridge$lambda.min)
beta <- ridge$glmnet.fit$beta[,best.lambda]
head(beta)

## identifying predictive features
df <- data.frame(coef = as.numeric(beta),
                word = names(beta), stringsAsFactors=F)

df <- df[order(df$coef),]
head(df[,c("coef", "word")], n=30)
paste(df$word[1:30], collapse=", ")
df <- df[order(df$coef, decreasing=TRUE),]
head(df[,c("coef", "word")], n=30)
paste(df$word[1:30], collapse=", ")
```

BONUS. Use the function `heatmapPlot` to run a Google maps on the point Tweets. 

 * Why are such a large concentration in uptown? 
 
 * Compared to the roads, why do the points tend to occur on intersections?

```{r}
heatmapPlot(tweets)
```
